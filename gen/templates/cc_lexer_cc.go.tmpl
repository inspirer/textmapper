{{ template "header" . -}}
{{ block "lexerIncludes" . -}}
#include "{{.Options.DirIncludePrefix}}{{.Options.FilenamePrefix}}lexer.h"

#include "{{.Options.AbslIncludePrefix}}/log/log.h"
#include "{{.Options.AbslIncludePrefix}}/strings/match.h"
{{ end -}}

namespace {{.Options.Namespace}} {
{{ block "onBeforeLexer" .}}{{end -}}
{{ template "lexerTables" .}}
{{ template "decodeRune" .}}
{{ template "lexerCtor" .}}
{{ template "lexerNext" .}}
{{ template "lexerRewind" .}}
{{ block "onAfterLexer" .}}{{end -}}
}  // namespace {{.Options.Namespace}}


{{- define "lexerTables" -}}
namespace {
constexpr int tmNumClasses = {{.Lexer.Tables.NumSymbols}};

{{ $runeType := bits .Lexer.Tables.NumSymbols -}}
{{ if gt .Lexer.Tables.LastMapEntry.Start 2048 -}}
// Latin-1 characters.
constexpr uint{{$runeType}}_t tmRuneClass[] = {
{{- int_array (.Lexer.Tables.SymbolArr 256) "\t" 79 -}}
};

constexpr int tmRuneClassLen = 256;
constexpr int tmFirstRule = {{.Lexer.Tables.ActionStart}};

struct MapRange {
  uint32_t lo;
  uint32_t hi;
  uint{{$runeType}}_t default_val;
  std::vector<uint{{$runeType}}_t> val;
};

const std::vector<MapRange> tmRuneRanges = {
{{ range .Lexer.Tables.CompressedMap 256}}  { {{- .Lo}}, {{.Hi}}, {{.DefaultVal}}, {{if .Vals}}{
{{- int_array .Vals "\t\t" 78}}  }{{else}}{}{{end -}} },
{{ end -}}
};

uint32_t mapRune(int32_t c) {
  uint32_t lo = 0;
  uint32_t hi = tmRuneRanges.size();
  while (lo < hi) {
    uint32_t m = lo + (hi-lo)/2;
    const MapRange& r = tmRuneRanges[m];
    if (c < r.lo) {
      hi = m;
    } else if (c >= r.hi) {
      lo = m + 1;
    } else {
      uint32_t i = c - r.lo;
      if (i < r.val.size()) {
        return static_cast<uint32_t>(r.val[i]);
      }
      return static_cast<uint32_t>(r.default_val);
    }
  }
  return {{.Lexer.Tables.LastMapEntry.Target}};
}

{{ else -}}
{{ $runeArr := .Lexer.Tables.SymbolArr 0 -}}
constexpr uint{{$runeType}}_t tmRuneClass[] = {
{{- int_array (.Lexer.Tables.SymbolArr 256) "\t" 79 -}}
};

constexpr int tmRuneClassLen = {{len $runeArr}};
constexpr int tmFirstRule = {{.Lexer.Tables.ActionStart}};

{{ end -}}
{{ if gt (len .Lexer.StartConditions) 1 -}}
constexpr int tmStateMap[] = {
{{- int_array .Lexer.Tables.StateMap "\t" 79 -}}
};

{{ end -}}
{{ if .Lexer.RuleToken -}}
constexpr int{{bits_per_element .Lexer.RuleToken}}_t tmToken[] = {
{{- int_array .Lexer.RuleToken "\t" 79 -}}
};

{{ end -}}
constexpr int{{bits_per_element .Lexer.Tables.Dfa}}_t tmLexerAction[] = {
{{- int_array .Lexer.Tables.Dfa "\t" 79 -}}
};
{{if .Lexer.Tables.Backtrack -}}

constexpr int tmBacktracking[] = {
{{ range .Lexer.Tables.Backtrack -}}
  {{.Action}}, {{.NextState}},{{if .Details}} // {{.Details}}{{end}}
{{ end -}}
};
{{ end -}}
}  // namespace
{{ end -}}

{{- define "decodeRune" -}}
constexpr uint32_t runeErr = 0xfffd;

inline uint32_t decodeRune(std::string_view input, int64_t& offset) {
  uint8_t b0 = input[offset++];
  if (b0 < 0x80) {
    return b0;  // ASCII
  }
  uint8_t head = (b0 >> 3) & 0xf;
  int sz =
      (0x3a550000 >> (head * 2)) & 3;  // 0b10xx -> 1, 0b110x -> 2, 0b1110 -> 3
  if (sz == 0 || offset + sz > input.size()) {
    return runeErr;
  }
  uint8_t b1 = input[offset++];
  if (b1 < 0x80 || b1 >= 0xc0) {
    return runeErr;
  }
  if (sz == 1) {
    return (static_cast<uint32_t>(b0) & 0x1F) << 6 | (b1 & 0x3F);
  }
  uint8_t b2 = input[offset++];
  if (b2 < 0x80 || b2 >= 0xc0) {
    return runeErr;
  }
  if (sz == 2) {
    return (static_cast<uint32_t>(b0) & 0xF) << 12 |
           (static_cast<uint32_t>(b1) & 0x3F) << 6 | (b2 & 0x3F);
  }
  uint8_t b3 = input[offset++];
  if (b3 < 0x80 || b3 >= 0xc0) {
    return runeErr;
  }
  return (static_cast<uint32_t>(b0) & 0x7) << 18 |
         (static_cast<uint32_t>(b1) & 0x3F) << 12 |
         (static_cast<uint32_t>(b2) & 0x3F) << 6 | (b3 & 0x3F);
}
{{end -}}

{{- define "lexerCtor" -}}
Lexer::Lexer(absl::string_view input_source) {
  source_ = input_source;
  if (absl::StartsWith(source_, bomSeq)) {
    offset_ += bomSeq.size();
  }
  Rewind(offset_);
}
{{end -}}

{{- define "lexerNext" -}}
Token Lexer::Next() {
{{ block "onBeforeNext" .}}{{end -}}
{{ $spaceRules := .SpaceActions -}}
{{ if or $spaceRules .Lexer.RuleToken -}}
restart:
{{ end -}}
{{ if .Options.TokenLine -}}
  token_line_ = line_;
{{ end -}}
{{ if .Options.TokenColumn -}}
  token_column_ = offset_ - line_offset_ + 1;
{{ end -}}
  token_offset_ = offset_;

  int state = {{ if gt (len .Lexer.StartConditions) 1 }}tmStateMap[static_cast<uint32_t>(start_state_)]{{else}}{{index .Lexer.Tables.StateMap 0}}{{end}};
{{ if .Lexer.ClassActions -}}
  uint32_t hash = 0;
{{ end -}}
{{ if .Lexer.Tables.Backtrack -}}
{{ if .Lexer.RuleToken -}}
  int backupRule = -1;
{{ else -}}
  Token backupToken = Token::EOI;
{{ end -}}
  uint64_t backupOffset;
{{ if .Lexer.ClassActions -}}
  uint32_t backupHash = hash;
{{ end -}}
{{ end -}}
  while (state >= 0) {
    int curr_class;
    if (input_rune_ < 0) {
      state = tmLexerAction[state * tmNumClasses];
{{ if .Lexer.Tables.Backtrack -}}
      if (state > tmFirstRule && state < 0) {
        state = (-1 - state) * 2;
{{ if .Lexer.RuleToken -}}
        backupRule = tmBacktracking[state];
{{ else -}}
        backupToken = Token(tmBacktracking[state]);
{{ end -}}
        backupOffset = offset_;
{{ if .Lexer.ClassActions -}}
        backupHash = hash;
{{ end -}}
        state = tmBacktracking[state + 1];
      }
{{ end -}}
      continue;
    } else if (input_rune_ < tmRuneClassLen) {
      curr_class = tmRuneClass[input_rune_];
    } else {
{{ if gt .Lexer.Tables.LastMapEntry.Start 2048 -}}
      curr_class = mapRune(input_rune_);
{{ else -}}
      curr_class = {{.Lexer.Tables.LastMapEntry.Target}};
{{ end -}}
    }
    state = tmLexerAction[state * tmNumClasses + curr_class];
    if (state > tmFirstRule) {
{{ if .Lexer.Tables.Backtrack -}}
      if (state < 0) {
        state = (-1 - state) * 2;
{{ if .Lexer.RuleToken -}}
        backupRule = tmBacktracking[state];
{{ else -}}
        backupToken = Token(tmBacktracking[state]);
{{ end -}}
        backupOffset = offset_;
{{ if .Lexer.ClassActions -}}
        backupHash = hash;
{{ end -}}
        state = tmBacktracking[state + 1];
      }
{{ end -}}
{{ if .Lexer.ClassActions -}}
      hash = hash * 31 + static_cast<uint32_t>(input_rune_);
{{end -}}
{{ if .Options.TokenLine -}}
      if (input_rune_ == '\n') {
        line_++;
{{ if or .Options.TokenLineOffset .Options.TokenColumn -}}
        line_offset_ = offset_;
{{ end -}}
      }
{{ end -}}

      // Scan the next character.
      offset_ = scan_offset_;
      if (offset_ < source_.size()) {
        input_rune_ = decodeRune(source_, scan_offset_);
      } else {
        input_rune_ = -1;
      }
    }
  }

{{ if .Lexer.RuleToken -}}
  int rule = tmFirstRule - state;
{{ else -}}
  Token tok = Token(tmFirstRule - state);
{{ end -}}
{{ if .Lexer.Tables.Backtrack -}}
recovered:
{{ end -}}
{{ if .Lexer.ClassActions -}}
  switch ({{if .Lexer.RuleToken}}rule{{else}}tok{{end}}) {
{{ range .Lexer.ClassActions -}}
{{ if $.Lexer.RuleToken -}}
  case {{sum .Action 2}}:
{{ else -}}
  case Token::{{(index $.Syms .Action).ID}}: {
{{ end -}}
{{ with string_switch .Custom -}}
    switch (hash & {{.Mask}}) {
{{ range .Cases -}}
    case {{.Value}}:
{{ range .Subcases -}}
      if (hash == {{hex .Hash}} && {{quote .Str}} == Text()) {
{{ if $.Lexer.RuleToken -}}
        rule = {{sum .Action 2}};
{{ else -}}
        tok = Token::{{(index $.Syms .Action).ID}};
{{ end -}}
        break;
      }
{{ end -}}
      break;
{{ end}}{{/* .Cases */ -}}
    }
    break;
{{ end -}}
{{ end}}{{/* .Lexer.ClassActions */ -}}
  default:
    break;
  }
{{ end -}}
{{ if .Lexer.RuleToken -}}

  Token tok = Token(tmToken[rule]);
  bool space = false;
{{ if .Lexer.Actions -}}
  switch (rule) {
  case 0:
{{ template "handleInvalidToken" . -}}
    break;
{{ range .Lexer.Actions -}}
  case {{sum .Action 2}}:{{if .Comments}} // {{join .Comments ", "}}{{end}}
{{ if .Space -}}
    space = true;
{{ end -}}
{{ if .Code -}}
{{lexer_action .Code}}
{{ end -}}
    break;
{{ end }}{{/* .Lexer.Actions */ -}}
  }
{{ else -}}
  if (rule == 0) {
{{ template "handleInvalidToken" . -}}
  }
{{ end -}}
  if (space) {
    goto restart;
  }
{{ else -}}
  switch (tok) {
  case Token::{{(index $.Syms .Lexer.InvalidToken).ID}}:
{{ template "handleInvalidToken" . -}}
    break;
{{ if $spaceRules -}}
  case {{range $i, $val := $spaceRules}}{{if gt $i 0}}, {{end}}Token({{$val}}){{end}}:
    goto restart;
{{ end -}}
    default:
      break;
  }
{{ end -}}
{{ block "onAfterNext" .}}{{end -}}
  return tok;
}
{{end -}}


{{- define "lexerRewind" -}}
void Lexer::Rewind(int64_t rewind_offset) {
{{ if .Options.TokenLine -}}
  if (rewind_offset < offset_) {
    for (int64_t i = rewind_offset; i < offset_; ++i) {
      if (source_[i] == '\n') {
        line_--;
      }
    }
  } else {
    if (rewind_offset > source_.size()) {
      rewind_offset = source_.size();
    }
    for (int64_t i = offset_; i < rewind_offset; ++i) {
      if (source_[i] == '\n') {
        line_++;
      }
    }
  }
{{ if or .Options.TokenLineOffset .Options.TokenColumn -}}
  // Looking for \n before and not at offset_.
  line_offset_ = 1 + source_.find_last_of('\n', offset_ - 1);
{{ end -}}

{{ end -}}
  // Scan the next character.
  scan_offset_ = rewind_offset;
  offset_ = rewind_offset;
  if (offset_ < source_.size()) {
    input_rune_ = decodeRune(source_, scan_offset_);
  } else {
    input_rune_ = -1;  // Invalid rune for end of input
  }
}
{{end -}}

{{- define "handleInvalidToken" -}}
{{ if .Lexer.Tables.Backtrack -}}
      if ({{if .Lexer.RuleToken}}backupRule{{else}}static_cast<int>(backupToken){{end}} >= 0) {
{{ if .Lexer.RuleToken -}}
        rule = backupRule;
{{ else -}}
        tok = backupToken;
{{ end -}}
{{ if .Lexer.ClassActions -}}
        hash = backupHash;
{{ end -}}
        Rewind(backupOffset);
      } else if (offset_ == token_offset_) {
        Rewind(scan_offset_);
      }
{{ if .Lexer.RuleToken -}}
      if (rule != 0) {
{{ else -}}
      if (tok != Token::{{(index $.Syms .Lexer.InvalidToken).ID}}) {
{{ end -}}
        goto recovered;
      }
{{ else -}}
      if (offset_ == token_offset_) {
        Rewind(scan_offset_);
      }
{{ end -}}
{{ end }}
